---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi, I am a postdoctoral researcher in cognitive neuroscience and speech perception at the University of Toronto Scarborough, working with [Dr. Philip Monahan](https://phijomo.github.io/) in the [Computation and Psycholinguistics Laboratory (CAP Lab)](https://www.utsc.utoronto.ca/labs/caplab/).

My research focuses on how the brain processes and represents speech sounds, using behavioral and EEG experiments, I study the encoding of speech sounds in typical and clinical populations, exploring questions like how phonological representations retain acoustic details and how factors such as typicality and perceptual context influence memory encoding.

<h2 id="active">
Research
</h2>

<style>
.project-box {
    border: 2px solid #ddd;
    border-radius: 10px;
    padding: 20px;
    margin: 20px 0;
    display: flex;
    align-items: center;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
}

.project-box img {
    max-width: 300px; /* Adjust as needed */
    max-height: 300px; /* Adjust as needed */
    border-radius: 10px;
    margin-right: 20px;
}

.project-box .content {
    flex-grow: 1;
}

.project-box h3 {
    margin: 0 0 10px 0;
}

.project-box p {
    margin: 0;
}
</style>


<div class="project-box">
    <img src="https://chaohanch.github.io/images/flap_icon.jpg" alt="Project Image">
    <div class="content">
        <h3>Universal and language-specific encoding of speech</h3>
        <p>How does the brain encode the same sound differently across languages? This project examines how language-specific phonological patterns shape neural representations of speech. Although the flap [ɾ] occurs in both English and Korean, its phonological status differs: in English, it patterns with [t]; in Korean, with [l]. Using EEG, we probe whether this phonological structuring influences how the brain encodes [ɾ], testing how abstract linguistic categories interact with early neural processing.</p>
    </div>
</div>


<div class="project-box">
    <img src="https://chaohanch.github.io/images/laryngeal_icon.jpg" alt="Project Image">
    <div class="content">
        <h3>Phonological encoding and phonetic cue weighting</h3>
        <p>How does the brain determine whether a sound is /g/ or /k/? The answer lies in how listeners weight different phonetic cues. For instance, voicing contrasts in English stops are primarily cued by voice onset time (VOT), with fundamental frequency (F0) serving as a secondary cue. In this project, we combines behavioral identification tasks with EEG recordings of mismatch negativity (MMN) to explore two key questions: 1.Can secondary cues like F0 contribute to the brain’s pre-attentive encoding of phonological categories? 2.Do individual differences in MMN responses reflect how listeners differentially weight these cues?</p>
    </div>
</div>
