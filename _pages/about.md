---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi, I am a postdoctoral researcher in cognitive neuroscience and speech perception at the University of Toronto Scarborough, working with [Dr. Philip Monahan](https://phijomo.github.io/) in the [Computation and Psycholinguistics Laboratory (CAP Lab)](https://www.utsc.utoronto.ca/labs/caplab/).

My research focuses on how the brain processes and represents speech sounds, using behavioral and EEG experiments, I study the encoding of speech sounds in typical and clinical populations, exploring questions like how phonological representations retain acoustic details and how factors such as typicality and perceptual context influence memory encoding.

<h2 id="active">
Research
</h2>

<style>
.project-box {
    border: 2px solid #ddd;
    border-radius: 10px;
    padding: 20px;
    margin: 20px 0;
    display: flex;
    align-items: center;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
}

.project-box img {
    max-width: 300px; /* Adjust as needed */
    max-height: 300px; /* Adjust as needed */
    border-radius: 10px;
    margin-right: 20px;
}

.project-box .content {
    flex-grow: 1;
}

.project-box h3 {
    margin: 0 0 10px 0;
}

.project-box p {
    margin: 0;
}
</style>


<div class="project-box">
    <img src="https://chaohanch.github.io/images/flap_icon.jpg" alt="Project Image">
    <div class="content">
        <h3>Universal and language-specific encoding of speech</h3>
        <p>Speech sounds are organized by shared articulatory and acoustic properties, but languages carve up the shared space in different ways. For example, the flap [ɾ] occurs in both English and Korean but patterns with different sounds: with [t] as allophones of /t/ in English, and with [l] as allophones of /ɾ/ in Korean. This project tests whether and how these language-specific phonological patterns leave measurable traces in the neural encoding of language-universal phonetic features, a key toward linking neurophysiology and linguistic theory.</p>
    </div>
</div>


<div class="project-box">
    <img src="https://chaohanch.github.io/images/laryngeal_icon.jpg" alt="Project Image">
    <div class="content">
        <h3>Categorical encoding and phonetic cue weighting</h3>
        <p>Not all phonetic cues are created equal—at least not in the brain. Speech contrasts like voicing are signaled by multiple phonetic cues, such as voice onset time (VOT) and fundamental frequency (F0), but listeners weight these cues differently. How is individual cue-weighting reflected in pre-attentive neural encoding? By combining behavioral categorization with EEG, we test whether primary and secondary phonetic cues differentially engage early neural responses—shedding light on how fine-grained acoustic detail interacts with abstract phonological representations in the brain.</p>
    </div>
</div>
