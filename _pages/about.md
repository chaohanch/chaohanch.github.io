---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi, I am a postdoctoral researcher in cognitive neuroscience and speech perception at the University of Toronto Scarborough, working with [Dr. Philip Monahan](https://phijomo.github.io/) in the [Computation and Psycholinguistics Laboratory (CAP Lab)](https://www.utsc.utoronto.ca/labs/caplab/).

My research focuses on how the brain processes and represents speech sounds, using behavioral and EEG experiments, I study the encoding of speech sounds in typical and clinical populations, exploring questions like how phonological representations retain acoustic details and how factors such as typicality and perceptual context influence memory encoding.

<h2 id="active">
Research
</h2>

<style>
.project-box {
    border: 2px solid #ddd;
    border-radius: 10px;
    padding: 20px;
    margin: 20px 0;
    display: flex;
    align-items: center;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
}

.project-box img {
    max-width: 300px; /* Adjust as needed */
    max-height: 300px; /* Adjust as needed */
    border-radius: 10px;
    margin-right: 20px;
}

.project-box .content {
    flex-grow: 1;
}

.project-box h3 {
    margin: 0 0 10px 0;
}

.project-box p {
    margin: 0;
}
</style>


<div class="project-box">
    <img src="https://chaohanch.github.io/images/flap_icon.jpg" alt="Project Image">
    <div class="content">
        <h3>Universal and language-specific encoding of speech</h3>
        <p>Speech sounds are organized by shared articulatory and acoustic properties, but languages carve up the shared space in different ways. For example, the flap [ɾ] occurs in both English and Korean but patterns with different sounds: with [t] as allophones of /t/ in English, and with [l] as allophones of /ɾ/ in Korean. We test whether and how these language-specific phonological patterns leave measurable traces in the neural encoding of language-universal physical properties, a key to linking neurophysiology and linguistic theory.</p>
    </div>
</div>


<div class="project-box">
    <img src="https://chaohanch.github.io/images/laryngeal_icon.jpg" alt="Project Image">
    <div class="content">
        <h3>Phonological encoding and phonetic cue weighting</h3>
        <p>How does the brain determine whether a sound is /g/ or /k/? The answer lies in how listeners weight different phonetic cues. For instance, voicing contrasts in English stops are primarily cued by voice onset time (VOT), with fundamental frequency (F0) serving as a secondary cue. In this project, we combines behavioral identification tasks with EEG recordings of mismatch negativity (MMN) to explore two key questions: 1.Can secondary cues like F0 contribute to the brain’s pre-attentive encoding of phonological categories? 2.Do individual differences in MMN responses reflect how listeners differentially weight these cues?</p>
    </div>
</div>
